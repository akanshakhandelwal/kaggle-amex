{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c39297b",
   "metadata": {
    "papermill": {
     "duration": 0.006596,
     "end_time": "2022-07-15T01:04:32.809326",
     "exception": false,
     "start_time": "2022-07-15T01:04:32.802730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using LGBM with Optuna for hyperparameter tuning. \n",
    "\n",
    "I hope everyone enjoyiong this competition, definitely I am, although couldn't commit enough. I noticed everyone trying their best to help each other for all new findings while competing. This competiton is also a good example for new joiners. After noticing that we don't have a good sample notebook on hyper-parameter tuning I thought I can share mine. This is solely for those new to optuna and thinking about implementing it in this comeptiton. From experts expecting feedback. Ofcourse, I open to any feedback and suggestion to improve the note book from anyone. \n",
    "\n",
    "\n",
    "### Optuna: \n",
    "Optuna can help you search the best parameters if you can specify the search space. it is easy to install in your exisitng data science stack. Detail can be found here: https://optuna.readthedocs.io/en/stable/index.html \n",
    "\n",
    "### Data Processing: \n",
    "1. Started with denoised data shared by Raddar. \n",
    " Data here: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    " Discussion and codes in this page: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
    "2. Features were generated by using aggreagation using code shared here: https://www.kaggle.com/code/ambrosm/amex-lightgbm-quickstart\n",
    "3. Data I shared here: https://www.kaggle.com/datasets/kmmohsin/amex-denoised-aggregated-features\n",
    "4. Actual contribution of this notebook is to integrate with Optuna and find some parameters that lead to 0.796 in LB using CPU. In GPU best I got 0.795. Parameters will be shared in next section. \n",
    "\n",
    "### Note: \n",
    "1. You can run this code with GPU as well, just have to change device type  = 'gpu'. \n",
    "2. GPU need a different set of parameters. Shared along with CPU parametes with inline comment. \n",
    "3. You will not be able to get best result if you just run the notebook as is. \n",
    "4. For best result please tweak the parameters close to mine shared in 5. \n",
    "   \n",
    "   change these lines to your desired search area\n",
    "   \n",
    "    n_est = trial.suggest_int(\"n_estimators\", 10, 100, step=10)\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", .01, .03, step=.01)\n",
    "\n",
    "5. Best parameters I got with these features in CPU, **OOF 0.796 and LB score 0.796.** \n",
    "\n",
    "       n_estimators= 4800,  \n",
    "       learning_rate= .01,  \n",
    "       reg_lambda=50,\n",
    "       min_child_samples=2400,\n",
    "       num_leaves = 95,  # in gpu try with 40\n",
    "       colsample_bytree=0.19,\n",
    "       max_bins = 511,   #  for gpu try with 255\n",
    "       random_state = 42,\n",
    "       n_jobs = 16  # number of physical cpu cores\n",
    "       # device= 'gpu'\n",
    "\n",
    "### Future Work: \n",
    "1. There might be other parameters to tune with Optuna, leaving it for others to work on it. \n",
    "2. Feature engineering. Leaving for toppers. \n",
    "\n",
    "\n",
    "### Disclaimer:\n",
    "1. Please tweak it to run for GPU with new set of parameters\n",
    "2. Parameters I found with 16 cores in my local machine. \n",
    "3. I have shared the code that can run in notebook without memory error. Only need to tweak for right parameters, which may run longer.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dbb23",
   "metadata": {
    "papermill": {
     "duration": 0.005146,
     "end_time": "2022-07-15T01:04:32.820449",
     "exception": false,
     "start_time": "2022-07-15T01:04:32.815303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf94a9f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-15T01:04:32.834881Z",
     "iopub.status.busy": "2022-07-15T01:04:32.834363Z",
     "iopub.status.idle": "2022-07-15T01:04:36.505339Z",
     "shell.execute_reply": "2022-07-15T01:04:36.503593Z"
    },
    "papermill": {
     "duration": 3.681472,
     "end_time": "2022-07-15T01:04:36.508559",
     "exception": false,
     "start_time": "2022-07-15T01:04:32.827087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import scipy.stats\n",
    "import warnings\n",
    "from colorama import Fore, Back, Style\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66af477",
   "metadata": {
    "papermill": {
     "duration": 0.005384,
     "end_time": "2022-07-15T01:04:36.519849",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.514465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7a3209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:04:36.533640Z",
     "iopub.status.busy": "2022-07-15T01:04:36.533139Z",
     "iopub.status.idle": "2022-07-15T01:04:36.539550Z",
     "shell.execute_reply": "2022-07-15T01:04:36.538227Z"
    },
    "papermill": {
     "duration": 0.016516,
     "end_time": "2022-07-15T01:04:36.542133",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.525617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config\n",
    "DATA_PATH = '../input/amex-data-integer-dtypes-parquet-format/'   # denoised data from raddar\n",
    "LABELS_PATH = '../input/amex-default-prediction/train_labels.csv' # original data sources\n",
    "\n",
    "TEST_FEAT_PATH = '../input/amex-denoised-aggregated-features/test_feat.parquet' # aggregated features I shared\n",
    "TRAIN_FEAT_PATH = '../input/amex-denoised-aggregated-features/train_feat.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56997cd",
   "metadata": {
    "papermill": {
     "duration": 0.005315,
     "end_time": "2022-07-15T01:04:36.553051",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.547736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00039243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:04:36.567552Z",
     "iopub.status.busy": "2022-07-15T01:04:36.566570Z",
     "iopub.status.idle": "2022-07-15T01:04:36.579323Z",
     "shell.execute_reply": "2022-07-15T01:04:36.578254Z"
    },
    "papermill": {
     "duration": 0.022937,
     "end_time": "2022-07-15T01:04:36.582111",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.559174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_data(read_from_cache=True):\n",
    "    train = pd.read_parquet(TRAIN_FEAT_PATH)\n",
    "    test = pd.read_parquet(TEST_FEAT_PATH)\n",
    "    return test, train\n",
    "\n",
    "def amex_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by describing prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted Gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted Gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted Gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('amex',\n",
    "            amex_metric(y_true, y_pred),\n",
    "            True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683057a",
   "metadata": {
    "papermill": {
     "duration": 0.005376,
     "end_time": "2022-07-15T01:04:36.593221",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.587845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optuna objective definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8b6b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:04:36.607115Z",
     "iopub.status.busy": "2022-07-15T01:04:36.606228Z",
     "iopub.status.idle": "2022-07-15T01:04:36.623659Z",
     "shell.execute_reply": "2022-07-15T01:04:36.622327Z"
    },
    "papermill": {
     "duration": 0.027923,
     "end_time": "2022-07-15T01:04:36.626738",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.598815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    target = pd.read_csv(LABELS_PATH).target.values\n",
    "    test, train = get_data(read_from_cache=True)\n",
    "    print(f\"target shape: {target.shape}, train shape: {train.shape}, test shape: {test.shape}\")\n",
    "    features = [f for f in train.columns if f != 'customer_ID' and f != 'target']\n",
    "    \n",
    "    n_est = trial.suggest_int(\"n_estimators\", 10, 30, step=10)\n",
    "    lr = trial.suggest_float(\"learning_rate\", .01, .02, step=.01)\n",
    "   \n",
    "    def my_booster(n_est, lr):\n",
    "        return LGBMClassifier(n_estimators= n_est,  # original 1200\n",
    "                   learning_rate= lr,  # original 0.03\n",
    "                   reg_lambda=50,\n",
    "                   min_child_samples=2400,\n",
    "                   num_leaves = 95,  # with cpu 95\n",
    "                   colsample_bytree=0.19,\n",
    "                   max_bins = 511,   # originally for CPU 511, for gpu 255\n",
    "                   random_state = 42,\n",
    "                   n_jobs = 16  # number of physical cpu cores\n",
    "                   # min_data_in_leaf = 1000, \n",
    "                   # device= 'gpu'\n",
    "                )    \n",
    "    \n",
    "    cv_folds = 5\n",
    "    ONLY_FIRST_FOLD = False\n",
    "    score_list, y_pred_list = [], []\n",
    "    kf = StratifiedKFold(n_splits=cv_folds)\n",
    "    \n",
    "    for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "        X_tr, X_va, y_tr, y_va, model = None, None, None, None, None\n",
    "        start_time = datetime.datetime.now()\n",
    "        X_tr = train.iloc[idx_tr][features]\n",
    "        X_va = train.iloc[idx_va][features]\n",
    "        y_tr = target[idx_tr]\n",
    "        y_va = target[idx_va]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=UserWarning)\n",
    "            model = my_booster(n_est, lr)\n",
    "            model.fit(X_tr, y_tr,\n",
    "                      eval_set = [(X_va, y_va)], \n",
    "                      eval_metric=[lgb_amex_metric],\n",
    "                      callbacks=[log_evaluation(10)])\n",
    "        X_tr, y_tr = None, None\n",
    "        y_va_pred = model.predict_proba(X_va, raw_score=True)\n",
    "        score = amex_metric(y_va, y_va_pred)\n",
    "        n_trees = model.best_iteration_\n",
    "        if n_trees is None: n_trees = model.n_estimators\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "              f\" {n_trees:5} trees |\"\n",
    "              f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "        score_list.append(score)\n",
    "\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")\n",
    "    return np.mean(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60ccf1",
   "metadata": {
    "papermill": {
     "duration": 0.005503,
     "end_time": "2022-07-15T01:04:36.638264",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.632761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed59f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:04:36.652345Z",
     "iopub.status.busy": "2022-07-15T01:04:36.651463Z",
     "iopub.status.idle": "2022-07-15T01:09:44.730907Z",
     "shell.execute_reply": "2022-07-15T01:09:44.728647Z"
    },
    "papermill": {
     "duration": 308.089683,
     "end_time": "2022-07-15T01:09:44.733752",
     "exception": false,
     "start_time": "2022-07-15T01:04:36.644069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-15 01:04:36,657]\u001b[0m A new study created in memory with name: no-name-b8cb477e-96c1-4efa-afa0-e574b44421bb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape: (458913,), train shape: (458913, 469), test shape: (924621, 469)\n",
      "[10]\tvalid_0's binary_logloss: 0.488114\tvalid_0's amex: 0.729313\n",
      "[20]\tvalid_0's binary_logloss: 0.431348\tvalid_0's amex: 0.736506\n",
      "[30]\tvalid_0's binary_logloss: 0.38933\tvalid_0's amex: 0.73983\n",
      "\u001b[32m\u001b[1mFold 0 | 00:30 |    30 trees |                Score = 0.73963\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.4877\tvalid_0's amex: 0.730007\n",
      "[20]\tvalid_0's binary_logloss: 0.430641\tvalid_0's amex: 0.735035\n",
      "[30]\tvalid_0's binary_logloss: 0.388466\tvalid_0's amex: 0.73766\n",
      "\u001b[32m\u001b[1mFold 1 | 00:31 |    30 trees |                Score = 0.73746\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.48788\tvalid_0's amex: 0.735276\n",
      "[20]\tvalid_0's binary_logloss: 0.430813\tvalid_0's amex: 0.741658\n",
      "[30]\tvalid_0's binary_logloss: 0.388549\tvalid_0's amex: 0.744718\n",
      "\u001b[32m\u001b[1mFold 2 | 00:31 |    30 trees |                Score = 0.74447\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.487749\tvalid_0's amex: 0.736298\n",
      "[20]\tvalid_0's binary_logloss: 0.430581\tvalid_0's amex: 0.742309\n",
      "[30]\tvalid_0's binary_logloss: 0.388257\tvalid_0's amex: 0.747195\n",
      "\u001b[32m\u001b[1mFold 3 | 00:30 |    30 trees |                Score = 0.74702\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.487524\tvalid_0's amex: 0.734196\n",
      "[20]\tvalid_0's binary_logloss: 0.430264\tvalid_0's amex: 0.741826\n",
      "[30]\tvalid_0's binary_logloss: 0.387848\tvalid_0's amex: 0.746649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-15 01:07:34,430]\u001b[0m Trial 0 finished with value: 0.7430070320187431 and parameters: {'n_estimators': 30, 'learning_rate': 0.02}. Best is trial 0 with value: 0.7430070320187431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mFold 4 | 00:31 |    30 trees |                Score = 0.74645\u001b[0m\n",
      "\u001b[32m\u001b[1mOOF Score:                       0.74301\u001b[0m\n",
      "target shape: (458913,), train shape: (458913, 469), test shape: (924621, 469)\n",
      "[10]\tvalid_0's binary_logloss: 0.488114\tvalid_0's amex: 0.729313\n",
      "\u001b[32m\u001b[1mFold 0 | 00:25 |    10 trees |                Score = 0.72907\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.4877\tvalid_0's amex: 0.730007\n",
      "\u001b[32m\u001b[1mFold 1 | 00:25 |    10 trees |                Score = 0.72978\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.48788\tvalid_0's amex: 0.735276\n",
      "\u001b[32m\u001b[1mFold 2 | 00:24 |    10 trees |                Score = 0.73503\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.487749\tvalid_0's amex: 0.736298\n",
      "\u001b[32m\u001b[1mFold 3 | 00:23 |    10 trees |                Score = 0.73608\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.487524\tvalid_0's amex: 0.734196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-15 01:09:44,723]\u001b[0m Trial 1 finished with value: 0.7327885173921829 and parameters: {'n_estimators': 10, 'learning_rate': 0.02}. Best is trial 0 with value: 0.7430070320187431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mFold 4 | 00:23 |    10 trees |                Score = 0.73398\u001b[0m\n",
      "\u001b[32m\u001b[1mOOF Score:                       0.73279\u001b[0m\n",
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 0.7430070320187431\n",
      "  Params: \n",
      "    n_estimators: 30\n",
      "    learning_rate: 0.02\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=2)  # change it to cover the search space\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b7160",
   "metadata": {
    "papermill": {
     "duration": 0.008568,
     "end_time": "2022-07-15T01:09:44.750873",
     "exception": false,
     "start_time": "2022-07-15T01:09:44.742305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that you know all the best parameters you can probably run with those best parameters to have fresh interpretation. Just clear up memories I will call garbage collector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c7500a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:09:44.771918Z",
     "iopub.status.busy": "2022-07-15T01:09:44.771393Z",
     "iopub.status.idle": "2022-07-15T01:09:45.003259Z",
     "shell.execute_reply": "2022-07-15T01:09:45.002039Z"
    },
    "papermill": {
     "duration": 0.245657,
     "end_time": "2022-07-15T01:09:45.006061",
     "exception": false,
     "start_time": "2022-07-15T01:09:44.760404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec7a66",
   "metadata": {
    "papermill": {
     "duration": 0.00793,
     "end_time": "2022-07-15T01:09:45.022747",
     "exception": false,
     "start_time": "2022-07-15T01:09:45.014817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and Infer with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1670d21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:09:45.045214Z",
     "iopub.status.busy": "2022-07-15T01:09:45.044266Z",
     "iopub.status.idle": "2022-07-15T01:13:25.044102Z",
     "shell.execute_reply": "2022-07-15T01:13:25.042474Z"
    },
    "papermill": {
     "duration": 220.015411,
     "end_time": "2022-07-15T01:13:25.047088",
     "exception": false,
     "start_time": "2022-07-15T01:09:45.031677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape: (458913,), train shape: (458913, 469), test shape: (924621, 469)\n",
      "[10]\tvalid_0's binary_logloss: 0.525976\tvalid_0's amex: 0.727389\n",
      "[20]\tvalid_0's binary_logloss: 0.48902\tvalid_0's amex: 0.732419\n",
      "[30]\tvalid_0's binary_logloss: 0.457844\tvalid_0's amex: 0.736497\n",
      "[40]\tvalid_0's binary_logloss: 0.432076\tvalid_0's amex: 0.738707\n",
      "[50]\tvalid_0's binary_logloss: 0.409634\tvalid_0's amex: 0.739711\n",
      "\u001b[32m\u001b[1mFold 0 | 00:33 |    50 trees |                Score = 0.73947\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.525716\tvalid_0's amex: 0.727602\n",
      "[20]\tvalid_0's binary_logloss: 0.48856\tvalid_0's amex: 0.732113\n",
      "[30]\tvalid_0's binary_logloss: 0.457256\tvalid_0's amex: 0.733427\n",
      "[40]\tvalid_0's binary_logloss: 0.431392\tvalid_0's amex: 0.735422\n",
      "[50]\tvalid_0's binary_logloss: 0.408896\tvalid_0's amex: 0.737463\n",
      "\u001b[32m\u001b[1mFold 1 | 00:33 |    50 trees |                Score = 0.73724\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.5259\tvalid_0's amex: 0.732635\n",
      "[20]\tvalid_0's binary_logloss: 0.488782\tvalid_0's amex: 0.738894\n",
      "[30]\tvalid_0's binary_logloss: 0.457436\tvalid_0's amex: 0.740203\n",
      "[40]\tvalid_0's binary_logloss: 0.43147\tvalid_0's amex: 0.743855\n",
      "[50]\tvalid_0's binary_logloss: 0.408915\tvalid_0's amex: 0.745499\n",
      "\u001b[32m\u001b[1mFold 2 | 00:33 |    50 trees |                Score = 0.74526\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.525768\tvalid_0's amex: 0.732697\n",
      "[20]\tvalid_0's binary_logloss: 0.488617\tvalid_0's amex: 0.739194\n",
      "[30]\tvalid_0's binary_logloss: 0.457254\tvalid_0's amex: 0.741225\n",
      "[40]\tvalid_0's binary_logloss: 0.431323\tvalid_0's amex: 0.74259\n",
      "[50]\tvalid_0's binary_logloss: 0.408712\tvalid_0's amex: 0.744724\n",
      "\u001b[32m\u001b[1mFold 3 | 00:33 |    50 trees |                Score = 0.74453\u001b[0m\n",
      "[10]\tvalid_0's binary_logloss: 0.525571\tvalid_0's amex: 0.731911\n",
      "[20]\tvalid_0's binary_logloss: 0.488322\tvalid_0's amex: 0.738148\n",
      "[30]\tvalid_0's binary_logloss: 0.456858\tvalid_0's amex: 0.741277\n",
      "[40]\tvalid_0's binary_logloss: 0.430891\tvalid_0's amex: 0.743497\n",
      "[50]\tvalid_0's binary_logloss: 0.408295\tvalid_0's amex: 0.74481\n",
      "\u001b[32m\u001b[1mFold 4 | 00:33 |    50 trees |                Score = 0.74464\u001b[0m\n",
      "\u001b[32m\u001b[1mOOF Score:                       0.74223\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target = pd.read_csv(LABELS_PATH).target.values\n",
    "test, train = get_data(read_from_cache=True)\n",
    "print(f\"target shape: {target.shape}, train shape: {train.shape}, test shape: {test.shape}\")\n",
    "features = [f for f in train.columns if f != 'customer_ID' and f != 'target']\n",
    "\n",
    "def my_booster(n_est, lr):\n",
    "    return LGBMClassifier(n_estimators= n_est,  # try 4800\n",
    "               learning_rate= lr,  # try 0.01\n",
    "               reg_lambda=50,\n",
    "               min_child_samples=2400,\n",
    "               num_leaves = 95,  # with cpu 95\n",
    "               colsample_bytree=0.19,\n",
    "               max_bins = 511,   # originally for CPU 511, for gpu 255\n",
    "               random_state = 42,\n",
    "               n_jobs = 16  # number of physical cpu cores\n",
    "               # min_data_in_leaf = 1000, \n",
    "               # device= 'gpu'\n",
    "            )    \n",
    "\n",
    "cv_folds = 5\n",
    "ONLY_FIRST_FOLD = False\n",
    "score_list, y_pred_list = [], []\n",
    "kf = StratifiedKFold(n_splits=cv_folds)\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, target)):\n",
    "    X_tr, X_va, y_tr, y_va, model = None, None, None, None, None\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_tr = train.iloc[idx_tr][features]\n",
    "    X_va = train.iloc[idx_va][features]\n",
    "    y_tr = target[idx_tr]\n",
    "    y_va = target[idx_va]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model = my_booster(50, .01)  # passing best params, try with 4800 and 0.01\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  eval_set = [(X_va, y_va)], \n",
    "                  eval_metric=[lgb_amex_metric],\n",
    "                  callbacks=[log_evaluation(10)])  # change to 100 for large number of trees\n",
    "    X_tr, y_tr = None, None\n",
    "    y_va_pred = model.predict_proba(X_va, raw_score=True)\n",
    "    score = amex_metric(y_va, y_va_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: n_trees = model.n_estimators\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    # inference\n",
    "    y_pred_list.append(model.predict_proba(test[features], raw_score=True))\n",
    "\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef4c56",
   "metadata": {
    "papermill": {
     "duration": 0.010878,
     "end_time": "2022-07-15T01:13:25.068482",
     "exception": false,
     "start_time": "2022-07-15T01:13:25.057604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission ready file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f64894b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T01:13:25.092015Z",
     "iopub.status.busy": "2022-07-15T01:13:25.091480Z",
     "iopub.status.idle": "2022-07-15T01:13:30.566327Z",
     "shell.execute_reply": "2022-07-15T01:13:30.565052Z"
    },
    "papermill": {
     "duration": 5.490862,
     "end_time": "2022-07-15T01:13:30.569626",
     "exception": false,
     "start_time": "2022-07-15T01:13:25.078764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'customer_ID': test.index,\n",
    "                        'prediction': np.mean(y_pred_list, axis=0)})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb18a0",
   "metadata": {
    "papermill": {
     "duration": 0.010065,
     "end_time": "2022-07-15T01:13:30.591206",
     "exception": false,
     "start_time": "2022-07-15T01:13:30.581141",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 551.674404,
   "end_time": "2022-07-15T01:13:32.332945",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-15T01:04:20.658541",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
